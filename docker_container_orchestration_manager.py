# -*- coding: utf-8 -*-
"""Docker Container Orchestration Manager

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, timedelta
import random
from collections import defaultdict

class ContainerManager:
    def __init__(self):
        self.containers = {}
        self.metrics_history = defaultdict(lambda: defaultdict(list))
        self.scaling_events = []
        self.health_checks = []

    def simulate_container_fleet(self, hours=24):
        """Simulate a fleet of containers"""
        services = {
            'nginx-web': {'replicas': 3, 'cpu_limit': 0.5, 'mem_limit': 512},
            'api-service': {'replicas': 5, 'cpu_limit': 1.0, 'mem_limit': 1024},
            'worker-queue': {'replicas': 2, 'cpu_limit': 0.75, 'mem_limit': 768},
            'redis-cache': {'replicas': 1, 'cpu_limit': 0.25, 'mem_limit': 256},
            'postgres-db': {'replicas': 1, 'cpu_limit': 2.0, 'mem_limit': 2048}
        }

        container_id = 1
        for service_name, config in services.items():
            for replica in range(config['replicas']):
                container_name = f"{service_name}-{replica+1}"
                self.containers[container_name] = {
                    'id': f"cont_{container_id:04d}",
                    'service': service_name,
                    'status': 'running',
                    'cpu_limit': config['cpu_limit'],
                    'mem_limit': config['mem_limit'],
                    'started_at': datetime.now() - timedelta(hours=random.randint(1, 72)),
                    'restarts': 0
                }
                container_id += 1

        # Simulate metrics over time
        for hour in range(hours):
            timestamp = datetime.now() - timedelta(hours=hours-hour)

            for container_name, container in self.containers.items():
                service = container['service']

                # Simulate different load patterns
                if 'api' in service:
                    # API services - variable load with peaks
                    base_cpu = 40 + 30 * np.sin(hour / 3) + random.uniform(-10, 10)
                    base_mem = 60 + 20 * np.sin(hour / 4) + random.uniform(-5, 5)
                    network_in = random.uniform(10, 100)
                    network_out = random.uniform(5, 80)
                elif 'worker' in service:
                    # Worker services - steady load
                    base_cpu = 50 + random.uniform(-15, 15)
                    base_mem = 55 + random.uniform(-10, 10)
                    network_in = random.uniform(5, 30)
                    network_out = random.uniform(5, 30)
                elif 'db' in service or 'redis' in service:
                    # Database/Cache - high memory, variable CPU
                    base_cpu = 30 + 40 * np.sin(hour / 2) + random.uniform(-5, 15)
                    base_mem = 75 + random.uniform(-5, 5)
                    network_in = random.uniform(20, 150)
                    network_out = random.uniform(20, 150)
                else:
                    # Web servers - moderate load
                    base_cpu = 35 + 25 * np.sin(hour / 3.5) + random.uniform(-8, 8)
                    base_mem = 45 + random.uniform(-10, 10)
                    network_in = random.uniform(30, 200)
                    network_out = random.uniform(50, 300)

                # Ensure values are within reasonable bounds
                cpu_usage = max(5, min(95, base_cpu))
                mem_usage = max(10, min(90, base_mem))

                # Calculate based on limits
                cpu_percent = (cpu_usage / 100) * container['cpu_limit'] * 100
                mem_mb = (mem_usage / 100) * container['mem_limit']

                # Add occasional health check failures
                health_status = 'healthy'
                if random.random() < 0.02:  # 2% chance of unhealthy
                    health_status = 'unhealthy'
                    self.health_checks.append({
                        'timestamp': timestamp,
                        'container': container_name,
                        'status': health_status
                    })

                # Add auto-scaling events
                if cpu_percent > 80 and random.random() < 0.1:
                    self.scaling_events.append({
                        'timestamp': timestamp,
                        'service': service,
                        'action': 'scale_up',
                        'trigger': 'high_cpu'
                    })

                self.metrics_history[container_name]['cpu'].append({
                    'timestamp': timestamp,
                    'value': cpu_percent,
                    'limit': container['cpu_limit'] * 100
                })
                self.metrics_history[container_name]['memory'].append({
                    'timestamp': timestamp,
                    'value': mem_mb,
                    'limit': container['mem_limit']
                })
                self.metrics_history[container_name]['network_in'].append({
                    'timestamp': timestamp,
                    'value': network_in
                })
                self.metrics_history[container_name]['network_out'].append({
                    'timestamp': timestamp,
                    'value': network_out
                })
                self.metrics_history[container_name]['health'].append({
                    'timestamp': timestamp,
                    'status': health_status
                })

    def generate_dashboard(self):
        """Generate container orchestration dashboard"""
        fig = plt.figure(figsize=(18, 12))
        fig.suptitle('Docker Container Orchestration Dashboard',
                     fontsize=20, fontweight='bold')

        container_names = list(self.containers.keys())

        # 1. Container Status Overview
        ax1 = plt.subplot(3, 3, 1)
        services = set([c['service'] for c in self.containers.values()])
        service_counts = {s: sum(1 for c in self.containers.values()
                                 if c['service'] == s) for s in services}

        colors = plt.cm.Set3(np.linspace(0, 1, len(services)))
        wedges, texts, autotexts = ax1.pie(service_counts.values(),
                                            labels=service_counts.keys(),
                                            autopct='%d', colors=colors, startangle=90)
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontweight('bold')
        ax1.set_title(f'Container Distribution ({len(container_names)} total)',
                     fontweight='bold')

        # 2. CPU Utilization Over Time
        ax2 = plt.subplot(3, 3, 2)
        # Show top 5 containers by average CPU
        avg_cpu = {}
        for container in container_names[:5]:
            cpu_data = self.metrics_history[container]['cpu']
            avg_cpu[container] = np.mean([d['value'] for d in cpu_data])
            times = [d['timestamp'] for d in cpu_data]
            values = [d['value'] for d in cpu_data]
            ax2.plot(times, values, label=container.split('-')[0], linewidth=2, alpha=0.7)

        ax2.set_ylabel('CPU Usage (%)', fontweight='bold')
        ax2.set_title('CPU Utilization Trends', fontweight='bold')
        ax2.legend(loc='best', fontsize=8)
        ax2.grid(True, alpha=0.3)
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)

        # 3. Memory Usage Over Time
        ax3 = plt.subplot(3, 3, 3)
        for container in container_names[:5]:
            mem_data = self.metrics_history[container]['memory']
            times = [d['timestamp'] for d in mem_data]
            values = [d['value'] for d in mem_data]
            ax3.plot(times, values, label=container.split('-')[0], linewidth=2, alpha=0.7)

        ax3.set_ylabel('Memory Usage (MB)', fontweight='bold')
        ax3.set_title('Memory Utilization Trends', fontweight='bold')
        ax3.legend(loc='best', fontsize=8)
        ax3.grid(True, alpha=0.3)
        plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)

        # 4. Resource Utilization Heatmap
        ax4 = plt.subplot(3, 3, 4)
        heatmap_data = []
        container_labels = []

        for container in container_names[:10]:
            cpu_data = self.metrics_history[container]['cpu']
            mem_data = self.metrics_history[container]['memory']

            avg_cpu = np.mean([d['value'] for d in cpu_data[-6:]])
            avg_mem_percent = (np.mean([d['value'] for d in mem_data[-6:]]) /
                              self.containers[container]['mem_limit']) * 100

            heatmap_data.append([avg_cpu, avg_mem_percent])
            container_labels.append(container[:15] + '...' if len(container) > 15
                                  else container)

        im = ax4.imshow(heatmap_data, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=100)
        ax4.set_xticks([0, 1])
        ax4.set_xticklabels(['CPU', 'Memory'])
        ax4.set_yticks(np.arange(len(container_labels)))
        ax4.set_yticklabels(container_labels, fontsize=8)
        ax4.set_title('Resource Utilization Heatmap', fontweight='bold')

        for i in range(len(container_labels)):
            for j in range(2):
                text = ax4.text(j, i, f'{heatmap_data[i][j]:.0f}%',
                              ha="center", va="center", color="black", fontweight='bold')

        plt.colorbar(im, ax=ax4, label='Utilization (%)')

        # 5. Network Traffic
        ax5 = plt.subplot(3, 3, 5)
        total_network_in = []
        total_network_out = []
        timestamps = []

        # Aggregate network traffic
        all_timestamps = set()
        for container in container_names:
            for data in self.metrics_history[container]['network_in']:
                all_timestamps.add(data['timestamp'])

        for ts in sorted(all_timestamps):
            net_in = sum(d['value'] for container in container_names
                        for d in self.metrics_history[container]['network_in']
                        if d['timestamp'] == ts)
            net_out = sum(d['value'] for container in container_names
                         for d in self.metrics_history[container]['network_out']
                         if d['timestamp'] == ts)
            timestamps.append(ts)
            total_network_in.append(net_in)
            total_network_out.append(net_out)

        ax5.plot(timestamps, total_network_in, label='Incoming',
                linewidth=2, color='#3498db', marker='o', markersize=4)
        ax5.plot(timestamps, total_network_out, label='Outgoing',
                linewidth=2, color='#e74c3c', marker='s', markersize=4)
        ax5.set_ylabel('Traffic (MB/s)', fontweight='bold')
        ax5.set_title('Network Traffic', fontweight='bold')
        ax5.legend()
        ax5.grid(True, alpha=0.3)
        plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45)

        # 6. Container Health Status
        ax6 = plt.subplot(3, 3, 6)
        if self.health_checks:
            health_times = [h['timestamp'] for h in self.health_checks]
            health_values = [1 if h['status'] == 'unhealthy' else 0
                           for h in self.health_checks]

            ax6.scatter(health_times, health_values, c='red', s=100,
                       marker='x', linewidths=3, label='Health Issues')
            ax6.set_ylabel('Status', fontweight='bold')
            ax6.set_yticks([0, 1])
            ax6.set_yticklabels(['Healthy', 'Unhealthy'])
            ax6.set_title(f'Health Check Events ({len(self.health_checks)} issues)',
                         fontweight='bold')
            ax6.grid(True, alpha=0.3)
            plt.setp(ax6.xaxis.get_majorticklabels(), rotation=45)
        else:
            ax6.text(0.5, 0.5, 'All Containers Healthy', ha='center', va='center',
                    fontsize=14, color='green', fontweight='bold',
                    transform=ax6.transAxes)
            ax6.set_title('Health Check Events', fontweight='bold')

        # 7. Auto-scaling Events
        ax7 = plt.subplot(3, 3, 7)
        if self.scaling_events:
            scale_times = [e['timestamp'] for e in self.scaling_events]
            scale_actions = [1 if e['action'] == 'scale_up' else -1
                           for e in self.scaling_events]

            colors_scale = ['green' if a == 1 else 'red' for a in scale_actions]
            ax7.scatter(scale_times, scale_actions, c=colors_scale, s=150, alpha=0.6)
            ax7.set_ylabel('Action', fontweight='bold')
            ax7.set_yticks([-1, 1])
            ax7.set_yticklabels(['Scale Down', 'Scale Up'])
            ax7.set_title(f'Auto-scaling Events ({len(self.scaling_events)} events)',
                         fontweight='bold')
            ax7.grid(True, alpha=0.3)
            plt.setp(ax7.xaxis.get_majorticklabels(), rotation=45)
        else:
            ax7.text(0.5, 0.5, 'No Scaling Events', ha='center', va='center',
                    fontsize=14, fontweight='bold', transform=ax7.transAxes)
            ax7.set_title('Auto-scaling Events', fontweight='bold')

        # 8. Resource Efficiency Score
        ax8 = plt.subplot(3, 3, 8)
        efficiency_scores = []
        service_labels = []

        for service in services:
            service_containers = [c for c, data in self.containers.items()
                                if data['service'] == service]

            total_cpu = 0
            total_mem = 0
            count = 0

            for container in service_containers:
                cpu_data = self.metrics_history[container]['cpu']
                mem_data = self.metrics_history[container]['memory']

                avg_cpu = np.mean([d['value'] for d in cpu_data[-6:]])
                avg_mem_percent = (np.mean([d['value'] for d in mem_data[-6:]]) /
                                  self.containers[container]['mem_limit']) * 100

                total_cpu += avg_cpu
                total_mem += avg_mem_percent
                count += 1

            if count > 0:
                # Efficiency: balance between utilization and over-provisioning
                avg_cpu = total_cpu / count
                avg_mem = total_mem / count

                # Optimal range is 50-70%
                cpu_efficiency = 100 - abs(avg_cpu - 60)
                mem_efficiency = 100 - abs(avg_mem - 60)
                efficiency = (cpu_efficiency + mem_efficiency) / 2

                efficiency_scores.append(efficiency)
                service_labels.append(service.split('-')[0])

        bars = ax8.barh(service_labels, efficiency_scores,
                       color='#1abc9c', alpha=0.7, edgecolor='black')
        ax8.set_xlabel('Efficiency Score', fontweight='bold')
        ax8.set_title('Resource Efficiency by Service', fontweight='bold')
        ax8.set_xlim(0, 100)
        ax8.grid(axis='x', alpha=0.3)

        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax8.text(width + 2, bar.get_y() + bar.get_height()/2,
                    f'{width:.0f}', ha='left', va='center', fontweight='bold')

        # 9. Container Uptime
        ax9 = plt.subplot(3, 3, 9)
        uptimes = []
        uptime_labels = []

        for container in container_names[:8]:
            uptime_hours = (datetime.now() -
                          self.containers[container]['started_at']).total_seconds() / 3600
            uptimes.append(uptime_hours)
            uptime_labels.append(container[:12] + '...' if len(container) > 12
                               else container)

        colors_uptime = plt.cm.viridis(np.linspace(0, 1, len(uptimes)))
        ax9.barh(uptime_labels, uptimes, color=colors_uptime, alpha=0.7, edgecolor='black')
        ax9.set_xlabel('Uptime (hours)', fontweight='bold')
        ax9.set_title('Container Uptime', fontweight='bold')
        ax9.grid(axis='x', alpha=0.3)

        plt.tight_layout()
        plt.savefig('container_orchestration_dashboard.png', dpi=300, bbox_inches='tight')
        print("‚úÖ Dashboard saved as 'container_orchestration_dashboard.png'")
        plt.show()

    def generate_report(self):
        """Generate text report"""
        print("\n" + "="*80)
        print(" "*20 + "CONTAINER ORCHESTRATION REPORT")
        print("="*80 + "\n")

        print(f"üê≥ Total Containers: {len(self.containers)}")
        print(f"üì¶ Unique Services: {len(set([c['service'] for c in self.containers.values()]))}")
        print(f"üîÑ Auto-scaling Events: {len(self.scaling_events)}")
        print(f"‚ù§Ô∏è  Health Check Issues: {len(self.health_checks)}")

        print(f"\nüìä Container Breakdown by Service:")
        services = set([c['service'] for c in self.containers.values()])
        for service in services:
            count = sum(1 for c in self.containers.values() if c['service'] == service)
            print(f"   {service:20s}: {count} replicas")

        print("\n" + "="*80 + "\n")

# Main execution
if __name__ == "__main__":
    print("üöÄ Starting Container Orchestration Manager...")

    manager = ContainerManager()
    print("üê≥ Simulating container fleet...")
    manager.simulate_container_fleet(hours=24)

    print("üìä Generating dashboard...")
    manager.generate_dashboard()

    manager.generate_report()

    print("‚úÖ Container management complete!")